{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a component\n",
    "\n",
    "In order to create a component which could be used in a ML pipeline you will need to write the necessary functions in a service file, create a proto file based on the services provided, generate the gRPC code and implement the client and the server. All of this should then be containerized and the container image (Docker image) can then be uploaded to dockerhub. From there you can upload the dockerimage together with the protofile to the AI builder platform where it can be used as part of a pipeline. We will now go more in depth into how to complete these steps.\n",
    "\n",
    "### 1. Writing the service. \n",
    "\n",
    "First you will need to decide on what kind of service you want or need. This could be for example data filtering, model training, making predictions etc. Once you have decided on the service you can pick any language supported by protobuffers that's suitable to implement the necessary functions. Protobuffers support C++, C#, Dart, Go, Java, Kotlin, Objective-C, Python and Ruby. The service should consists of different functions that take some input and produce an output. \n",
    "\n",
    "### 2. Make a proto file\n",
    "\n",
    "Next you need to define the protofile based on the services. As discussed in the protocol buffers notebook, you need to take into consideration the data that is necessary in order to use the functions you have implemented. You should define the necessary message structures as well as the service that will be provided according to the instructions in the protocol buffers notebook. \n",
    "\n",
    "### 3. Generate gRPC code\n",
    "\n",
    "Once you have defined the protofile you can use it to generate the necessary gRPC code for your service. The process of generating the code as well as the resulting code will differ depending on the language you have chosen for your application. As mentioned in the gRPC file, the generated code will contain code for the service interface, the client and the server.\n",
    "\n",
    "### 4. Client and server\n",
    "\n",
    "Next you will need to implement the client and the server using the generated gRPC code. The server should implement the services defined in the protofile. If you already defined them when creating the service, you can simply import the functions. The client should have a stub which should've been generated in the previous step. The stub allows for easy communication between the client and the server. \n",
    "\n",
    "### 5. License\n",
    "\n",
    "Before creating the docker image you will need to include an apache 2.0 license as gRPC falls under it. \n",
    "\n",
    "### 6. Prepare the docker file and test the service\n",
    "\n",
    "Next you can create the dockerfile. You will need to cop over the necessary code, run installation commands and write an entrypoint command. After aving written the dockerfile you can test the service by building and running the server and then running the client separatly. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
